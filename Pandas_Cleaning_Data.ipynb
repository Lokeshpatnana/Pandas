{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lokeshpatnana/Pandas/blob/main/Pandas_Cleaning_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtyPJLjoEyUS"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AF3vu8QRfcB"
      },
      "source": [
        "# Downloading and Loading Datasets\n",
        "Downloading all the required csv files and loading the data into the dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3OjByf8RfcB"
      },
      "source": [
        "# eCommerce Dataset\n",
        "!wget https://nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com/otg_prod/media/Tech_4.0/AI_ML/Datasets/shopping_data.csv\n",
        "\n",
        "shopping_df = pd.read_csv('shopping_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIYeqaK_M8wZ"
      },
      "source": [
        "# Covid Dataset\n",
        "!wget https://nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com/otg_prod/media/Tech_4.0/AI_ML/Datasets/italy-covid-daywise.csv\n",
        "\n",
        "covid_df = pd.read_csv('italy-covid-daywise.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNKwxH46M8lC"
      },
      "source": [
        "# Stackoverflow Survey Dataset\n",
        "!wget https://nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com/otg_prod/media/Tech_4.0/AI_ML/Datasets/survey_results_public.csv\n",
        "\n",
        "survey_df = pd.read_csv('survey_results_public.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PuJZuRAM8Za"
      },
      "source": [
        "# Film Dataset\n",
        "!wget https://nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com/otg_prod/media/Tech_4.0/AI_ML/Datasets/film.csv\n",
        "\n",
        "films_df = pd.read_csv('film.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnscSniYZzX8"
      },
      "source": [
        "# Cleaning Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL4XMZVcd_et"
      },
      "source": [
        "## Handling Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-Z60KlF2hAi"
      },
      "source": [
        "### pd.DataFrame.isna\n",
        "* `pd.DataFrame.isna()`\n",
        "  * Return a boolean same-sized object indicating if the values are NA.\n",
        "  * `None` or `numpy.NaN` are considered as NA values.\n",
        "  * Characters such as `''` or `numpy.inf` are not considered as NA values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqhYMQ1BdTe5"
      },
      "source": [
        "shopping_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAjx02hG1lIY"
      },
      "source": [
        "shopping_df.isna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM7sCxE32WtN"
      },
      "source": [
        "shopping_df[\"Order ID\"].isna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GY9S7AjEX3X"
      },
      "source": [
        "**To find the number of `Nan` objects within the given series**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gh7A_MnETqY"
      },
      "source": [
        "shopping_df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scfY20rX8tmn"
      },
      "source": [
        "### pd.DataFrame.fillna\n",
        "* `pd.DataFrame.fillna(value=None, limit=None)`\n",
        "  * Fill NA/NaN values with the given value.\n",
        "  * `value` is used to fill Nan. It can be a single value(e.g. 0) or a dict, Series, DataFrame etc. It cannot be a list.\n",
        "  * `limit` is the maximum number of entries along the entire axis where NaNs will be filled.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6voOGro2BOnj"
      },
      "source": [
        "shopping_df.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW4V_XmICrJN"
      },
      "source": [
        "shopping_df.fillna('MISSING')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdMyuBpHebQL"
      },
      "source": [
        "**You can fill appropriate missing values for each of the columns**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM7hs6xrCxOo"
      },
      "source": [
        "values = {'Order ID': '00', 'Product': 'xxx', 'Quantity Ordered': '1', 'Price Each': '100', 'Order Date': '04/07/19 22:30', 'Purchase Address': 'xxxxx'}\n",
        "\n",
        "shopping_df.fillna(value=values).head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJfyjbjCDvJ1"
      },
      "source": [
        "values = {'Order ID': '00', 'Product': 'xxx', 'Quantity Ordered': '1', 'Price Each': '100', 'Order Date': '04/07/19 22:30', 'Purchase Address': 'xxxxx'}\n",
        "\n",
        "shopping_df.fillna(value=values, limit=3).head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Er7tVwDWjpp"
      },
      "source": [
        "### pd.DataFrame.dropna\n",
        "\n",
        "* `pd.DataFrame.dropna(axis=0, how='any', subset=None, inplace=False)`\n",
        "  * Removes missing values\n",
        "  * Returns a DataFrame with the NA entries dropped from it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBtQ5nB9XZMH"
      },
      "source": [
        "shopping_df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPsdXkSiX69f"
      },
      "source": [
        "Drop the rows where all the elements are missing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgk3aYNUX8-H"
      },
      "source": [
        "shopping_df.dropna(how='all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoGiUpfZXsEV"
      },
      "source": [
        "Drop the columns where at least one element is missing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofOC0MmXXvyB"
      },
      "source": [
        "shopping_df.dropna(axis='columns', how=\"any\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsbFRftNYRFh"
      },
      "source": [
        "**Can also define the specific columns to look for the missing values using the `subset` parameter**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLTpLMIhYS59"
      },
      "source": [
        "shopping_df.dropna(subset=['Order ID', 'Product'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2VlDrwpio_s"
      },
      "source": [
        "**More Examples:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABPw2_4DwD-H"
      },
      "source": [
        "people = {\n",
        "    'first': ['Kristen', 'Maxine', 'John', 'Emma', np.nan, None, 'NA'],\n",
        "    'last': ['Carol', 'Williams', 'Smith', 'Collins', np.nan, np.nan, 'Missing'],\n",
        "    'email': ['KristenC@gmail.com', 'maxine@gmail.com', 'John.S@email.com', None, np.nan, 'Anonymous@email.com', 'NA'],\n",
        "    'age': ['33', '55', '63', '36', None, None, 'Missing']\n",
        "}\n",
        "\n",
        "people_df = pd.DataFrame(people)\n",
        "people_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85QdJwqugWjm"
      },
      "source": [
        "people_df.isna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym2HV85f_E1L"
      },
      "source": [
        "If both the `email` and `last` is `NA`, then drops the row."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szdYIFw2xN44"
      },
      "source": [
        "people_df.dropna(axis='index', how='all', subset=['last', 'email'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UBeQKcD-79j"
      },
      "source": [
        "If either the `email` or `last` is `NA`, then drops the row."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B429YSSjx9zA"
      },
      "source": [
        "people_df.dropna(axis='index', how='any', subset=['last', 'email'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqPN1hHrvP-C"
      },
      "source": [
        "### Using `replace` to handle other missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcVrM_6_vkTS"
      },
      "source": [
        "people = {\n",
        "    'first': ['Kristen', 'Missing', 'John', 'Emma', np.nan, None],\n",
        "    'last': ['Carol', 'Williams', 'Smith', 'Collins', np.nan, np.nan],\n",
        "    'email': ['NA', 'maxine@gmail.com', 'John.S@email.com', None, np.nan, 'Anonymous@email.com'],\n",
        "    'age': ['33', '55', '63', '36', None, None]\n",
        "}\n",
        "\n",
        "people_df = pd.DataFrame(people)\n",
        "people_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-67H9Q7yNko"
      },
      "source": [
        "people_df.replace('NA', np.nan, inplace=True)\n",
        "people_df.replace('Missing', np.nan, inplace=True)\n",
        "\n",
        "people_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGXNw31jhZLc"
      },
      "source": [
        "people_df.isna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7BKhdzSDf8D"
      },
      "source": [
        "**We can also specify additional strings to be recognized as `NA/NaN` while loading the data itself**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFgRZe68hoq2"
      },
      "source": [
        "pd.read_csv?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjJKqqTc1OI1"
      },
      "source": [
        "na_vals = ['NA', 'Missing']\n",
        "\n",
        "survey_df = pd.read_csv('survey_results_public.csv', index_col='Respondent', na_values=na_vals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYm1cgmpiuNx"
      },
      "source": [
        "## Handling Duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl3JnAdMPC8k"
      },
      "source": [
        "### pd.DataFrame.duplicated\n",
        "* `pd.DataFrame.duplicated(subset=None, keep='first')`\n",
        "  * It returns a boolean series for each of the duplicated rows.\n",
        "  * `subset` is used to only consider certain columns for identifying duplicates.\n",
        "  * `keep` determines which duplicates (if any) to mark.\n",
        "    * `first` marks all the duplicates as True except for the first occurrence.\n",
        "    * `last` marks all the duplicates as True except for the last occurrence.\n",
        "    * `False` marks all the duplicates as True.\n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeEeyuZLzVmX"
      },
      "source": [
        "shopping_df.loc[25:35]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mW9_t1xzljG"
      },
      "source": [
        "shopping_df[25:35].duplicated()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00xwqR8u8CHy"
      },
      "source": [
        "shopping_df[25:35].duplicated(keep='last')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8gzPyTwTFwt"
      },
      "source": [
        "shopping_df[25:35].duplicated(subset=['Product'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tx-21kQTyM_"
      },
      "source": [
        "### pd.DataFrame.drop_duplicates\n",
        "* `pd.drop_duplicates(subset=None, keep='first', inplace=False)`\n",
        "  * It returns a dataframe with the duplicated rows removed.\n",
        "  * `subset` is used to only consider certain columns for identifying duplicates.\n",
        "  * `keep` determines which duplicates (if any) to mark.\n",
        "    * `first` marks all the duplicates as True except for the first occurrence.\n",
        "    * `last` marks all the duplicates as True except for the last occurrence.\n",
        "    * `False` marks all the duplicates as True."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K7j1-bkRW-4"
      },
      "source": [
        "shopping_sample = shopping_df[25:35]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIkFAFdr1Hks"
      },
      "source": [
        "shopping_sample.drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtxlSY87785o"
      },
      "source": [
        "shopping_sample.drop_duplicates(keep='last')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4lIm-me1Hkw"
      },
      "source": [
        "shopping_sample.drop_duplicates(subset=['Product'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j38ifSYjXJY"
      },
      "source": [
        "## Changing Datatypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dol0sjh9LG6B"
      },
      "source": [
        "### Using `astype`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD-J6Dx335il"
      },
      "source": [
        "shopping_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzNKAGJkEkMR"
      },
      "source": [
        "shopping_df['Price Each'].astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1Qq-GLqpR9_"
      },
      "source": [
        "people = {\n",
        "    'first': ['Kristen', 'Maxine', 'John', 'Emma', np.nan, None],\n",
        "    'last': ['Carol', 'Williams', 'Smith', 'Collins', np.nan, np.nan],\n",
        "    'email': ['KristenC@gmail.com', 'maxine@gmail.com', 'John.S@email.com', None, np.nan, 'Anonymous@email.com'],\n",
        "    'age': ['33', '55', '63', '36', None, None]\n",
        "}\n",
        "\n",
        "people_df = pd.DataFrame(people)\n",
        "people_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS8xYHKPCVni"
      },
      "source": [
        "The following code raises an error, because `age` is a string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJdV-szlzQkA"
      },
      "source": [
        "people_df['age'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLzC-FsqCfJh"
      },
      "source": [
        "If we try to convert it to `int` it still raises an error, because there are `NaN` values in the `age` column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7VkywBKz0Dg"
      },
      "source": [
        "people_df['age'] = people_df['age'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLqjw1FlCt10"
      },
      "source": [
        "Internally, `NaN` values are represented as `float`. So, we can **convert the age column into `float`** instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWn9JUys0UWi"
      },
      "source": [
        "people_df['age'] = people_df['age'].astype(float)\n",
        "people_df['age'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dihv3ScnBPPk"
      },
      "source": [
        "The following code raises an error, because `YearsCode` contains string values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRbGguoowEK3"
      },
      "source": [
        "survey_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4lra1g73QQk"
      },
      "source": [
        "survey_df['YearsCode'] = survey_df['YearsCode'].astype('float')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK2yHMpM3oH3"
      },
      "source": [
        "survey_df['YearsCode'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6p8AtcK3_V4"
      },
      "source": [
        "survey_df['YearsCode'].replace('Less than 1 year', 0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97ethQVJ4OkL"
      },
      "source": [
        "survey_df['YearsCode'].replace('More than 50 years', 55, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDn7Mdyt4Yj3"
      },
      "source": [
        "survey_df['YearsCode'] = survey_df['YearsCode'].astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qitdlxho4bOB"
      },
      "source": [
        "survey_df['YearsCode'].median()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWDpyT6W_wHe"
      },
      "source": [
        "**Note:** We can convert everything in the dataframe to a single datatype at once, using `dataframe.astype(dtype)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOrwxh3YLh2b"
      },
      "source": [
        "### Converting into datetime objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJAVu7Cv6SpA"
      },
      "source": [
        "shopping_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAn2Jx2zB2Ha"
      },
      "source": [
        "* The data type of `Order Date` is currently `object`.\n",
        "* It can be converted into a `datetime` column using the `pd.to_datetime` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbgGBT2DLhgX"
      },
      "source": [
        "shopping_df['Order Date'] = pd.to_datetime(shopping_df['Order Date'])\n",
        "shopping_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s7xgk8iGK22"
      },
      "source": [
        "### Adding new columns related to Datetime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fRj1JwfL512"
      },
      "source": [
        "data = shopping_df.copy()\n",
        "\n",
        "data['Hour'] = data['Order Date'].dt.hour\n",
        "data['Minute'] = data['Order Date'].dt.minute\n",
        "data['second'] = data['Order Date'].dt.second\n",
        "data['Day'] = data['Order Date'].dt.day\n",
        "data['Month'] = data['Order Date'].dt.month\n",
        "data['Year'] = data['Order Date'].dt.year\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BEcKey0QFiw"
      },
      "source": [
        "data['Order Date'].dt.day_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x69DsBPMnOs"
      },
      "source": [
        "# Try It Yourself"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w03spf8MMlPm"
      },
      "source": [
        "\n",
        "For the following questions, use the **Stack Overflow** dataset.\n",
        "1. Fill the Nan values in the `age` column with 0.\n",
        "2. Drop the columns which have NaN values.\n",
        "3. Change the datatype of the `age` column to `int32`.\n",
        "\n",
        "For the following questions, use the **Covid** dataset.\n",
        "\n",
        "4. Convert the `date` column into a datetime object.\n",
        "5. Add three new columns: `day`, `month` and `year`.\n",
        "6. Mark all the duplicate years as `True` except for the last occurence."
      ]
    }
  ]
}